/*
 * TACHFILETO ENTERPRISE - TERMINOLOGY NORMALIZER V1.0
 * ==================================================
 * Ch·ª©c nƒÉng: Chu·∫©n h√≥a thu·∫≠t ng·ªØ k·∫ø to√°n/x√¢y d·ª±ng Ti·∫øng Vi·ªát
 * Thu·∫≠t to√°n: Jaro-Winkler Fuzzy Matching (ng∆∞·ª°ng 0.85)
 */

use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use strsim::jaro_winkler;
use tauri::command;

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NormalizedTerm {
    pub original: String,
    pub standardized: String,
    pub category: String,
}

#[command]
pub fn cmd_normalize_descriptions(
    descriptions: Vec<String>,
) -> Result<Vec<NormalizedTerm>, String> {
    let result = descriptions
        .iter()
        .map(|desc| GLOBAL_NORMALIZER.normalize(desc))
        .collect();
    Ok(result)
}

pub struct TerminologyNormalizer {
    // Map bi·∫øn th·ªÉ -> Chu·∫©n
    term_mapping: HashMap<String, String>,
    // Map Chu·∫©n -> Nh√≥m (material, labor, etc.)
    category_mapping: HashMap<String, String>,
}

impl TerminologyNormalizer {
    pub fn new() -> Self {
        let mut term_mapping = HashMap::new();

        // --- CHI PH√ç NGUY√äN V·∫¨T LI·ªÜU ---
        term_mapping.insert("cp nvl".to_string(), "chi ph√≠ nguy√™n v·∫≠t li·ªáu".to_string());
        term_mapping.insert(
            "cp nguy√™n v·∫≠t li·ªáu".to_string(),
            "chi ph√≠ nguy√™n v·∫≠t li·ªáu".to_string(),
        );
        term_mapping.insert(
            "nguyen vat lieu".to_string(),
            "chi ph√≠ nguy√™n v·∫≠t li·ªáu".to_string(),
        );
        term_mapping.insert("v·∫≠t t∆∞".to_string(), "chi ph√≠ nguy√™n v·∫≠t li·ªáu".to_string());

        // --- CHI PH√ç NH√ÇN C√îNG ---
        term_mapping.insert("cp nh√¢n c√¥ng".to_string(), "chi ph√≠ nh√¢n c√¥ng".to_string());
        term_mapping.insert("cp nhan cong".to_string(), "chi ph√≠ nh√¢n c√¥ng".to_string());
        term_mapping.insert("ti·ªÅn c√¥ng".to_string(), "chi ph√≠ nh√¢n c√¥ng".to_string());
        term_mapping.insert("ti·ªÅn l∆∞∆°ng".to_string(), "chi ph√≠ nh√¢n c√¥ng".to_string());
        term_mapping.insert(
            "nh√¢n c√¥ng x√¢y d·ª±ng".to_string(),
            "chi ph√≠ nh√¢n c√¥ng".to_string(),
        );

        // --- V·∫¨N CHUY·ªÇN ---
        term_mapping.insert("vc".to_string(), "v·∫≠n chuy·ªÉn".to_string());
        term_mapping.insert("c∆∞·ªõc v·∫≠n chuy·ªÉn".to_string(), "v·∫≠n chuy·ªÉn".to_string());
        term_mapping.insert("ph√≠ v·∫≠n chuy·ªÉn".to_string(), "v·∫≠n chuy·ªÉn".to_string());

        let mut category_mapping = HashMap::new();
        category_mapping.insert("chi ph√≠ nguy√™n v·∫≠t li·ªáu".to_string(), "v·∫≠t t∆∞".to_string());
        category_mapping.insert("chi ph√≠ nh√¢n c√¥ng".to_string(), "nh√¢n c√¥ng".to_string());
        category_mapping.insert("v·∫≠n chuy·ªÉn".to_string(), "logistics".to_string());

        Self {
            term_mapping,
            category_mapping,
        }
    }

    pub fn normalize(&self, description: &str) -> NormalizedTerm {
        let cleaned = self.clean_text(description);
        let standardized = self.standardize_term(&cleaned);
        let category = self.categorize(&standardized);

        NormalizedTerm {
            original: description.to_string(),
            standardized,
            category,
        }
    }

    fn clean_text(&self, text: &str) -> String {
        text.to_lowercase().trim().to_string()
    }

    fn standardize_term(&self, term: &str) -> String {
        if let Some(mapped) = self.term_mapping.get(term) {
            return mapped.clone();
        }

        let mut best_score = 0.82; // THRESHOLD: Lowered to 0.82 for better Vietnamese matching
        let mut best_match = None;

        for (key, value) in &self.term_mapping {
            let score = jaro_winkler(term, key);
            if score > best_score {
                best_score = score;
                best_match = Some(value.clone());
            }
        }

        best_match.unwrap_or_else(|| term.to_string())
    }

    fn categorize(&self, standardized_term: &str) -> String {
        self.category_mapping
            .get(standardized_term)
            .cloned()
            .unwrap_or_else(|| "kh√°c".to_string())
    }
}

lazy_static::lazy_static! {
    pub static ref GLOBAL_NORMALIZER: TerminologyNormalizer = TerminologyNormalizer::new();
}

// ============================================================================
// üß™ TEST SUITE V2.5.1 - TERMINOLOGY NORMALIZER
// ============================================================================

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_normalize_exact_match_nvl() {
        let normalizer = TerminologyNormalizer::new();
        let result = normalizer.normalize("cp nvl");

        assert_eq!(result.standardized, "chi ph√≠ nguy√™n v·∫≠t li·ªáu");
        assert_eq!(result.category, "v·∫≠t t∆∞");
        assert_eq!(result.original, "cp nvl");
    }

    #[test]
    fn test_normalize_exact_match_labor() {
        let normalizer = TerminologyNormalizer::new();
        let result = normalizer.normalize("ti·ªÅn c√¥ng");

        assert_eq!(result.standardized, "chi ph√≠ nh√¢n c√¥ng");
        assert_eq!(result.category, "nh√¢n c√¥ng");
    }

    #[test]
    fn test_normalize_fuzzy_match() {
        let normalizer = TerminologyNormalizer::new();

        // "cp nguy√™n v·∫≠t li·ªáu" g·∫ßn v·ªõi "cp nvl"
        let result = normalizer.normalize("cp nguyen vat lieu");
        assert_eq!(result.standardized, "chi ph√≠ nguy√™n v·∫≠t li·ªáu");
        assert_eq!(result.category, "v·∫≠t t∆∞");
    }

    #[test]
    fn test_normalize_case_insensitive() {
        let normalizer = TerminologyNormalizer::new();

        let result1 = normalizer.normalize("CP NVL");
        let result2 = normalizer.normalize("Cp Nvl");
        let result3 = normalizer.normalize("cp nvl");

        assert_eq!(result1.standardized, result2.standardized);
        assert_eq!(result2.standardized, result3.standardized);
    }

    #[test]
    fn test_normalize_whitespace_trimming() {
        let normalizer = TerminologyNormalizer::new();

        let result = normalizer.normalize("  ti·ªÅn c√¥ng  ");
        assert_eq!(result.standardized, "chi ph√≠ nh√¢n c√¥ng");
    }

    #[test]
    fn test_normalize_unknown_term() {
        let normalizer = TerminologyNormalizer::new();

        // Thu·∫≠t ng·ªØ ho√†n to√†n kh√¥ng match
        let result = normalizer.normalize("xyz abc 123");
        assert_eq!(result.standardized, "xyz abc 123");
        assert_eq!(result.category, "kh√°c");
    }

    #[test]
    fn test_normalize_transport() {
        let normalizer = TerminologyNormalizer::new();

        let result1 = normalizer.normalize("vc");
        let result2 = normalizer.normalize("ph√≠ v·∫≠n chuy·ªÉn");

        assert_eq!(result1.standardized, "v·∫≠n chuy·ªÉn");
        assert_eq!(result1.category, "logistics");
        assert_eq!(result2.standardized, "v·∫≠n chuy·ªÉn");
        assert_eq!(result2.category, "logistics");
    }

    #[test]
    fn test_cmd_normalize_descriptions_batch() {
        let descriptions = vec![
            "cp nvl".to_string(),
            "ti·ªÅn c√¥ng".to_string(),
            "vc".to_string(),
        ];

        let result = cmd_normalize_descriptions(descriptions).unwrap();

        assert_eq!(result.len(), 3);
        assert_eq!(result[0].standardized, "chi ph√≠ nguy√™n v·∫≠t li·ªáu");
        assert_eq!(result[1].standardized, "chi ph√≠ nh√¢n c√¥ng");
        assert_eq!(result[2].standardized, "v·∫≠n chuy·ªÉn");
    }

    #[test]
    fn test_jaro_winkler_threshold() {
        let normalizer = TerminologyNormalizer::new();

        // "cp nhan cong" should fuzzy match "cp nh√¢n c√¥ng" with threshold 0.82
        let result = normalizer.normalize("cp nhan cong");

        println!(
            "DEBUG: standardized='{}', category='{}'",
            result.standardized, result.category
        );

        // Should fuzzy match to labor cost
        assert_eq!(result.standardized, "chi ph√≠ nh√¢n c√¥ng");
        assert_eq!(result.category, "nh√¢n c√¥ng");
    }
}

// ============================================================================
// üìä COLUMN HEADER NORMALIZER - DASHBOARD INTEGRATION
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ColumnNormalizationResult {
    pub original_name: String,
    pub normalized_name: String,
    pub column_type: ColumnType,
}

#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub enum ColumnType {
    Amount,     // C·ªôt ti·ªÅn: th√†nh ti·ªÅn, t·ªïng c·ªông, thanh_tien
    Calculated, // C·ªôt t√≠nh to√°n: kh·ªëi l∆∞·ª£ng t√≠nh to√°n, KLTT
    Measured,   // C·ªôt ƒëo l∆∞·ªùng: kh·ªëi l∆∞·ª£ng th·ª±c t·∫ø, KLTT
    Status,     // C·ªôt tr·∫°ng th√°i: trang_thai, tinh_trang
    Other,      // C·ªôt kh√°c
}

impl TerminologyNormalizer {
    /// V3.1: THI·∫æT QU√ÇN LU·∫¨T - √âp m·ªçi t√™n c·ªôt th√†nh ASCII snake_case chu·∫©n h·ªá th·ªëng
    /// S·ª≠ d·ª•ng deunicode ƒë·ªÉ chuy·ªÉn ƒë·ªïi Vietnamese -> ASCII
    pub fn normalize_column_name(&self, column_name: &str) -> ColumnNormalizationResult {
        use deunicode::deunicode;

        // 1. Chu·∫©n h√≥a tri·ªát ƒë·ªÉ: "H·∫†NG M·ª§C" -> "hang_muc"
        let system_key = {
            let no_accents = deunicode(column_name);
            no_accents
                .to_lowercase()
                .chars()
                .map(|c| if c.is_alphanumeric() { c } else { ' ' })
                .collect::<String>()
                .split_whitespace()
                .filter(|s| !s.is_empty())
                .collect::<Vec<_>>()
                .join("_")
        };

        // 2. Ph√¢n lo·∫°i d·ª±a tr√™n Key ƒë√£ "s·∫°ch" ho√†n to√†n (ASCII only)
        let (final_key, col_type) = match system_key.as_str() {
            k if k.contains("thanh_tien")
                || k.contains("tong_cong")
                || k.contains("thanh_toan") =>
            {
                ("thanh_tien".to_string(), ColumnType::Amount)
            }
            k if k.contains("don_gia") || k.contains("gia") && k.contains("don") => {
                ("don_gia".to_string(), ColumnType::Amount)
            }
            k if k.contains("tinh_toan") || k.contains("kltt") || k.contains("du_toan") => {
                ("khoi_luong_tinh_toan".to_string(), ColumnType::Calculated)
            }
            k if k.contains("thuc_te") || k.contains("do_luong") => {
                ("khoi_luong_thuc_te".to_string(), ColumnType::Measured)
            }
            k if k.contains("trang_thai") || k.contains("status") => {
                ("trang_thai".to_string(), ColumnType::Status)
            }
            k if k.contains("hang_muc") || k.contains("dien_giai") || k.contains("mo_ta") => {
                ("hang_muc".to_string(), ColumnType::Other)
            }
            k if k.contains("khoi_luong") || k.contains("so_luong") => {
                ("khoi_luong".to_string(), ColumnType::Other)
            }
            k if k.contains("don_vi") || k == "dvt" => ("don_vi".to_string(), ColumnType::Other),
            k if k == "stt" || k == "tt" || k.contains("so_thu_tu") => {
                ("stt".to_string(), ColumnType::Other)
            }
            k if k.contains("ghi_chu") => ("ghi_chu".to_string(), ColumnType::Other),
            _ => (system_key.clone(), ColumnType::Other),
        };

        println!(
            "[Column Normalizer V3.1] '{}' ‚Üí '{}'",
            column_name, final_key
        );

        ColumnNormalizationResult {
            original_name: column_name.to_string(),
            normalized_name: final_key,
            column_type: col_type,
        }
    }

    /// Chu·∫©n h√≥a to√†n b·ªô DataFrame columns
    pub fn normalize_dataframe_columns(
        &self,
        df: &mut polars::prelude::DataFrame,
    ) -> Result<Vec<ColumnNormalizationResult>, String> {
        use polars::prelude::*;

        let original_cols: Vec<String> = df
            .get_column_names()
            .iter()
            .map(|s| s.to_string())
            .collect();

        let mut results = Vec::new();
        let mut rename_map = Vec::new();

        for col in &original_cols {
            let norm_result = self.normalize_column_name(col);
            results.push(norm_result.clone());

            if norm_result.normalized_name != *col {
                rename_map.push((col.clone(), norm_result.normalized_name.clone()));
            }
        }

        // √Åp d·ª•ng rename cho DataFrame
        for (old_name, new_name) in rename_map {
            if df.column(&old_name).is_ok() {
                let _ = df.rename(&old_name, new_name.as_str().into());
                println!("[Column Normalizer] '{}' ‚Üí '{}'", old_name, new_name);
            }
        }

        Ok(results)
    }
}

/// Tauri command - Normalize column names
#[command]
pub fn cmd_normalize_columns(
    column_names: Vec<String>,
) -> Result<Vec<ColumnNormalizationResult>, String> {
    let result = column_names
        .iter()
        .map(|col| GLOBAL_NORMALIZER.normalize_column_name(col))
        .collect();
    Ok(result)
}

// ============================================================================
// üß™ TEST SUITE - COLUMN NORMALIZER
// ============================================================================

#[cfg(test)]
mod column_tests {
    use super::*;

    #[test]
    fn test_normalize_column_amount() {
        let normalizer = TerminologyNormalizer::new();

        let result = normalizer.normalize_column_name("Th√†nh ti·ªÅn (VNƒê)");
        assert_eq!(result.normalized_name, "thanh_tien");
        assert_eq!(result.column_type, ColumnType::Amount);
    }

    #[test]
    fn test_normalize_column_calculated() {
        let normalizer = TerminologyNormalizer::new();

        let result = normalizer.normalize_column_name("KL T√≠nh To√°n");
        assert_eq!(result.normalized_name, "khoi_luong_tinh_toan");
        assert_eq!(result.column_type, ColumnType::Calculated);
    }

    #[test]
    fn test_normalize_column_measured() {
        let normalizer = TerminologyNormalizer::new();

        let result = normalizer.normalize_column_name("ƒêo L∆∞·ªùng Th·ª±c T·∫ø");
        assert_eq!(result.normalized_name, "khoi_luong_thuc_te");
        assert_eq!(result.column_type, ColumnType::Measured);
    }

    #[test]
    fn test_normalize_column_status() {
        let normalizer = TerminologyNormalizer::new();

        let result = normalizer.normalize_column_name("Tr·∫°ng Th√°i");
        assert_eq!(result.normalized_name, "trang_thai");
        assert_eq!(result.column_type, ColumnType::Status);
    }

    #[test]
    fn test_normalize_column_other() {
        let normalizer = TerminologyNormalizer::new();

        let result = normalizer.normalize_column_name("Ghi Ch√∫");
        assert_eq!(result.column_type, ColumnType::Other);
        assert!(result.normalized_name.contains("ghi"));
    }

    #[test]
    fn test_cmd_normalize_columns() {
        let columns = vec![
            "Th√†nh ti·ªÅn".to_string(),
            "T√≠nh to√°n".to_string(),
            "Status".to_string(),
        ];

        let results = cmd_normalize_columns(columns).unwrap();

        assert_eq!(results.len(), 3);
        assert_eq!(results[0].column_type, ColumnType::Amount);
        assert_eq!(results[1].column_type, ColumnType::Calculated);
        assert_eq!(results[2].column_type, ColumnType::Status);
    }
}
